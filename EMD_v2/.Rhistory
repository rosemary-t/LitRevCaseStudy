mc_rel <- get_reliability(MC_fcs, horizon, mutual_times$target_time, Nboots, "MC")
emd_rel <- get_reliability(EMD_fcs, horizon, mutual_times$target_time, Nboots, "EMD")
reliability_dt <- rbind(p_rel, var_rel, mc_rel, emd_rel)
fwrite(reliability_dt, file=paste0("./zone",zone, "_h",horizon,"_reliability.csv"))
forecasts <- VAR_fcs
## timestamps are the target times we want to evaluate for
rowinds <- forecasts[[2]][(Horizon==horizon) & (target_time %in% timestamps), which=TRUE]
rel <- reliability(qrdata=forecasts[[1]][rowinds,], realisations = forecasts[[2]][rowinds, ActualPower], bootstrap=nb, plot.it=T)
View(VAR_fcs)
View(VAR_fcs)
VAR_fcs[[1]]
hist(VAR_fcs[[1]]$q20)
hist(VAR_fcs[[1]]$q50)
View(var_rel)
get_reliability <- function(forecasts, horizon, timestamps, nb, model){
## timestamps are the target times we want to evaluate for
rowinds <- forecasts[[2]][(Horizon==horizon) & (target_time %in% timestamps), which=TRUE]
rel <- reliability(qrdata=forecasts[[1]][rowinds,], realisations = forecasts[[2]][rowinds, ActualPower], bootstrap=nb, plot.it=T)
rel <- as.data.table(rel)
rel[, flat_empirical := Empirical-Nominal]
rel[, flat_upper := upper-Nominal]
rel[, flat_lower := lower-Nominal]
rel[, Model := model]
return(rel)
}
mc_rel <- get_reliability(MC_fcs, horizon, mutual_times$target_time, Nboots, "MC")
p_rel <- get_reliability(persistence_fcs, horizon, mutual_times$target_time, Nboots, "Persistence")
emd_rel <- get_reliability(EMD_fcs, horizon, mutual_times$target_time, Nboots, "EMD")
require(data.table)
require(ProbCast)
require(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
zone <- 4
horizon <- 3
models <- c("Persistence", "VAR", "MC", "EMD")
Nboots <- 500 # number of times to bootstrap resample
## load all the different model forecasts for this zone
load(file=paste0("../persistence/zone", zone, "_forecasts.rda"))
load(file=paste0("../VAR/final_quantiles_zone",zone,".rda"))
load(file=paste0("../MC/test_forecasts_zone",zone,".rda"))
load(file=paste0("../EMD_v2/final_quantiles_zone",zone,".rda"))
times1 <- merge(persistence_fcs[[2]][Horizon==horizon, .(issue_time, target_time)], VAR_fcs[[2]][Horizon==horizon, .(issue_time, target_time)])
times2 <- merge(MC_fcs[[2]][Horizon==horizon, .(issue_time, target_time)], EMD_fcs[[2]][Horizon==horizon, .(issue_time, target_time)])
mutual_times <- merge(times1, times2)
get_reliability <- function(forecasts, horizon, timestamps, nb, model){
## timestamps are the target times we want to evaluate for
rowinds <- forecasts[[2]][(Horizon==horizon) & (target_time %in% timestamps), which=TRUE]
rel <- reliability(qrdata=forecasts[[1]][rowinds,], realisations = forecasts[[2]][rowinds, ActualPower], bootstrap=nb, plot.it=T)
rel <- as.data.table(rel)
rel[, flat_empirical := Empirical-Nominal]
rel[, flat_upper := upper-Nominal]
rel[, flat_lower := lower-Nominal]
rel[, Model := model]
return(rel)
}
p_rel <- get_reliability(persistence_fcs, horizon, mutual_times$target_time, Nboots, "Persistence")
var_rel <- get_reliability(VAR_fcs, horizon, mutual_times$target_time, Nboots, "VAR")
mc_rel <- get_reliability(MC_fcs, horizon, mutual_times$target_time, Nboots, "MC")
emd_rel <- get_reliability(EMD_fcs, horizon, mutual_times$target_time, Nboots, "EMD")
require(data.table)
require(ProbCast)
require(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
zone <- 4
horizon <- 3
models <- c("Persistence", "VAR", "MC", "EMD")
Nboots <- 500 # number of times to bootstrap resample
## how about just the constant variance model??
load(file=paste0("../VAR/zone",zone,"_qs_constvar.rda"))
test_rel <- get_reliability(VAR_fcs, horizon, VAR_fcs[[2]][Horizon==horizon, target_time], Nboots, "VAR")
get_reliability <- function(forecasts, horizon, timestamps, nb, model){
## timestamps are the target times we want to evaluate for
rowinds <- forecasts[[2]][(Horizon==horizon) & (target_time %in% timestamps), which=TRUE]
rel <- reliability(qrdata=forecasts[[1]][rowinds,], realisations = forecasts[[2]][rowinds, ActualPower], bootstrap=nb, plot.it=T)
rel <- as.data.table(rel)
rel[, flat_empirical := Empirical-Nominal]
rel[, flat_upper := upper-Nominal]
rel[, flat_lower := lower-Nominal]
rel[, Model := model]
return(rel)
}
test_rel <- get_reliability(VAR_fcs, horizon, VAR_fcs[[2]][Horizon==horizon, target_time], Nboots, "VAR")
rm(list=ls())
require(data.table)
require(ProbCast)
require(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
zone <- 4
horizon <- 3
models <- c("Persistence", "VAR", "MC", "EMD")
Nboots <- 500 # number of times to bootstrap resample
load(file=paste0("../VAR/zone",zone,"_qs_expsmoothvar.rda"))
get_reliability <- function(forecasts, horizon, timestamps, nb, model){
## timestamps are the target times we want to evaluate for
rowinds <- forecasts[[2]][(Horizon==horizon) & (target_time %in% timestamps), which=TRUE]
rel <- reliability(qrdata=forecasts[[1]][rowinds,], realisations = forecasts[[2]][rowinds, ActualPower], bootstrap=nb, plot.it=T)
rel <- as.data.table(rel)
rel[, flat_empirical := Empirical-Nominal]
rel[, flat_upper := upper-Nominal]
rel[, flat_lower := lower-Nominal]
rel[, Model := model]
return(rel)
}
test_rel <- get_reliability(VAR_fcs, horizon, VAR_fcs[[2]][Horizon==horizon, target_time], Nboots, "VAR")
require(data.table)
require(forecast)
require(rstudioapi)
require(doParallel)
require(ProbCast)
setwd(dirname(getActiveDocumentContext()$path))
zones <- c(1:10)
horizons <- c(1:6) # forecast 1 to 6 hours ahead
split_date <- as.POSIXct("2012-12-31 12:00") # split the training/testing data here
eps <- 0.01
LL <- log(eps/(1-eps)) # lower and upper limits in transformed space.
UL <- log((1-eps)/eps)
qs <- seq(0.05, 0.95, 0.05) # quantiles we will produce forecasts for.
load("../VAR/all_sites_power.rda") # this is power in transformed space already
setnames(alldata, 'timestamp', 'target_time') # so this matches with training_mean_fcs colnames.
z <- 1
## load the site mean forecasts
load(paste0("./mean_forecasts_zone",z,".rda"))
## want to get residuals for each zone.
power_fcts <- alldata[target_time %in% all_mean_fcs$target_time] # keep only the timestamps we also have forecasts for
## find the residuals
zone_data <- merge(power_fcts[,.(target_time, power=get(paste0("zone",z,"power")))],
all_mean_fcs[, .(issue_time, target_time, Horizon, meanfcs=mean_fc)], by='target_time')
View(zone_data)
View(power_fcts)
zone_data[,errors :=(power-meanfcs)]
View(zone_data)
zonedata <- zone_data
H <- 2
zone_h_ts <- zonedata[Horizon==H]
View(zone_h_ts)
View(zone_h_ts)
zone_h_ts <- zonedata[Horizon==H]
zone_h_ts <- zone_h_ts[order(issue_time)]
horizon_fcs <- copy(zone_h_ts[issue_time>splitdate, .(issue_time,target_time)])
splitdate <- split_date
horizon_fcs <- copy(zone_h_ts[issue_time>splitdate, .(issue_time,target_time)])
View(horizon_fcs)
test_times <- horizon_fcs$issue_time
it <- test_times[1]
plot(zone_h_ts$issue_time, zone_h_ts$errors)
plot(zone_h_ts$issue_time, zone_h_ts$errors, type='l')
plot(zone_h_ts[c(1:200),issue_time], zone_h_ts[c(1:200), errors], type='l')
testzone <- zone_h_ts[order(power)]
plot(zone_h_ts[c(1:200),issue_time], zone_h_ts[c(1:200), errors], type='l')
plot(testzone[c(1:200),issue_time], testzone[c(1:200), errors], type='l')
require(data.table)
require(forecast)
require(rstudioapi)
require(doParallel)
require(ProbCast)
setwd(dirname(getActiveDocumentContext()$path))
zones <- c(1:10)
horizons <- c(1:6) # forecast 1 to 6 hours ahead
split_date <- as.POSIXct("2012-12-31 12:00") # split the training/testing data here
eps <- 0.01
LL <- log(eps/(1-eps)) # lower and upper limits in transformed space.
UL <- log((1-eps)/eps)
qs <- seq(0.05, 0.95, 0.05) # quantiles we will produce forecasts for.
load("../VAR/all_sites_power.rda") # this is power in transformed space already
setnames(alldata, 'timestamp', 'target_time') # so this matches with training_mean_fcs colnames.
z <- 1
## load the site mean forecasts
load(paste0("./mean_forecasts_zone",z,".rda"))
## want to get residuals for each zone.
power_fcts <- alldata[target_time %in% all_mean_fcs$target_time] # keep only the timestamps we also have forecasts for
## find the residuals
zone_data <- merge(power_fcts[,.(target_time, power=get(paste0("zone",z,"power")))],
all_mean_fcs[, .(issue_time, target_time, Horizon, meanfcs=mean_fc)], by='target_time')
zone_data[,errors :=(power-meanfcs)]
zone_h_ts <- zone_data[Horizon==2]
zone_h_ts <- zone_h_ts[order(issue_time)]
test1 <- zone_h_ts[issue_time <= it, errors]
horizon_times <- copy(zone_h_ts[issue_time>splitdate, .(issue_time,target_time)])
splitdate <- split_date
horizon_times <- copy(zone_h_ts[issue_time>splitdate, .(issue_time,target_time)])
it <- horizon_times[1, issue_time]
test1 <- zone_h_ts[issue_time <= it, errors]
sort_horizon_fcs <- zone_h_ts[issue_time <= it]
sortednow <- sort_horizon_fcs[order(issue_time)]
identical(sort_horizon_fcs, sortednow)
identical(test1, sortednow$errors)
# fit exponential smoothing to all data before it
modelfit <- ses(ts(zone_h_ts[issue_time <= it, errors]), h=1, inital='optimal')
View(modelfit)
horizon_fcs[(issue_time==it) & (target_time==zone_h_ts[issue_time==it, target_time]), "varfc" := modelfit$mean]
horizon_fcs <- copy(zone_h_ts[issue_time>splitdate, .(issue_time,target_time)])
test_times <- horizon_fcs$issue_time
horizon_fcs[(issue_time==it) & (target_time==zone_h_ts[issue_time==it, target_time]), "varfc" := modelfit$mean]
View(modelfit)
tail(ts(zone_h_ts[issue_time <= it, errors]),5)
View(modelfit)
0.2839155*modelfit$par$alpha
modelfit$par$alpha
modelfit$par
modelfit$model$par
modelfit$model$par$alpha
modelfit$model$par[1]
modelfit$model$par[1]*0.2839155
it <- test_times[100]
# fit exponential smoothing to all data before it
modelfit <- ses(ts(zone_h_ts[issue_time <= it, errors]), h=1, inital='optimal')
tail(ts(zone_h_ts[issue_time <= it, errors]),5)
View(modelfit)
################ function to get exponential smoothing forecasts of variance ################
horizon_var_fcs <- function(zonedata, H, splitdate){
require(data.table)
require(forecast)
zone_h_ts <- zonedata[Horizon==H]
zone_h_ts <- zone_h_ts[order(issue_time)]
horizon_fcs <- copy(zone_h_ts[issue_time>splitdate, .(issue_time,target_time)])
test_times <- horizon_fcs$issue_time
for (it in test_times){
# fit exponential smoothing to all data before it
modelfit <- ses(ts(zone_h_ts[issue_time <= it, errors]), h=1, inital='optimal')
horizon_fcs[(issue_time==it) & (target_time==zone_h_ts[issue_time==it, target_time]), "varfc" := modelfit$mean]
}
return(horizon_fcs)
}
H <- 3
horizon_var_fcs(zone_data, H)
horizon_var_fcs(zone_data, H, split_date)
result <- horizon_var_fcs(zone_data, H, split_date)
warnings()
View(result)
plot(result[c(200:400), issue_time], result[c(200:400), varfc])
plot(result[c(200:400), issue_time], result[c(200:400), varfc], type='l')
plot(result[c(200:400), issue_time], abs(result[c(200:400), varfc]), type='l')
mean(abs(result$varfc))
View(zone_data)
variance_fcs <- result
meanvardt <- merge(zone_data, variance_fcs, by=c("issue_time", "target_time")) # means and variances in one data.table.
View(meanvardt)
plot(meanvardt[c(100:200), target_time], meanvardt[c(100:200), errors], type='l')
lines(meanvardt[c(100:200), target_time], meanvardt[c(100:200), varfc], type='l', col='red')
plot(meanvardt[c(100:105), target_time], meanvardt[c(100:105), errors], type='l')
lines(meanvardt[c(100:105), target_time], meanvardt[c(100:105), varfc], type='l', col='red')
require(data.table)
require(forecast)
require(rstudioapi)
require(doParallel)
require(ProbCast)
setwd(dirname(getActiveDocumentContext()$path))
zones <- c(1:10)
horizons <- c(1:6) # forecast 1 to 6 hours ahead
split_date <- as.POSIXct("2012-12-31 12:00") # split the training/testing data here
eps <- 0.01
LL <- log(eps/(1-eps)) # lower and upper limits in transformed space.
UL <- log((1-eps)/eps)
qs <- seq(0.05, 0.95, 0.05) # quantiles we will produce forecasts for.
load("../VAR/all_sites_power.rda") # this is power in transformed space already
setnames(alldata, 'timestamp', 'target_time') # so this matches with training_mean_fcs colnames.
z <- 1
## load the site mean forecasts
load(paste0("./mean_forecasts_zone",z,".rda"))
## want to get residuals for each zone.
power_fcts <- alldata[target_time %in% all_mean_fcs$target_time] # keep only the timestamps we also have forecasts for
## find the residuals
zone_data <- merge(power_fcts[,.(target_time, power=get(paste0("zone",z,"power")))],
all_mean_fcs[, .(issue_time, target_time, Horizon, meanfcs=mean_fc)], by='target_time')
zone_data[,errors :=(power-meanfcs)]
zone_h_ts <- zone_data
zone_h_ts <- zonedata[Horizon==H]
zone_h_ts <- zone_data[Horizon==3]
zone_h_ts <- zone_h_ts[order(issue_time)]
horizon_fcs <- copy(zone_h_ts[issue_time>splitdate, .(issue_time,target_time)])
splitdate <- split_date
horizon_fcs <- copy(zone_h_ts[issue_time>splitdate, .(issue_time,target_time)])
test_times <- horizon_fcs$issue_time
test_times <- horizon_fcs$target_time
test_times <- horizon_fcs$issue_time
it <- test_times[150]
# fit exponential smoothing to all data before it
data <-zone_h_ts[target_time < it,]
View(data)
# fit exponential smoothing to all data before it
data <-zone_h_ts[issue_time <= it,]
View(data)
# fit exponential smoothing to all data before it
data <-zone_h_ts[target_time <= it,]
View(data)
# fit exponential smoothing to all data before it
data <-zone_h_ts[target_time <= it,]
View(data)
modelfit <- ses(ts(zone_h_ts[target_time <= it, errors]), h=1, inital='optimal')
View(modelfit)
print (tail(modelfit$x))
View(modelfit)
forecast(modelfit, 3)
forecast(modelfit, h=3)
modelfit <- ses(ts(zone_h_ts[target_time <= it, errors]), h=3, inital='optimal')
forecast(modelfit, h=3)
plot(c(1:20), tail(modelfit$fitted, 20))
plot(c(1:20), tail(modelfit$fitted, 20), type='l')
lines(c(1:20), tail(modelfit$x,20), type='l', col='red')
abline(h=modelfit$mean)
tail(modelfit$x,1) - modelfit$mean
tail(modelfit$x,1)
-0.4014373 - modelfit$mean
modelfit <- ses(ts(zone_h_ts[target_time <= it, errors]), h=1, inital='optimal')
modelfit <- ses(ts(zone_h_ts[target_time <= it, errors]), h=1, inital='optimal')
horizon_fcs[(issue_time==it), "varfc" := modelfit$mean]
View(horizon_fcs)
################ function to get exponential smoothing forecasts of variance ################
horizon_var_fcs <- function(zonedata, H, splitdate){
require(data.table)
require(forecast)
zone_h_ts <- zonedata[Horizon==H]
zone_h_ts <- zone_h_ts[order(issue_time)]
horizon_fcs <- copy(zone_h_ts[issue_time>splitdate, .(issue_time,target_time)])
test_times <- horizon_fcs$target_time
for (it in test_times){
# fit exponential smoothing to all data where we have forecast and actual power before it (ie before target_time<=it)
data <-zone_h_ts[target_time <= it,]
modelfit <- ses(ts(zone_h_ts[target_time <= it, errors]), h=1, inital='optimal')
horizon_fcs[(issue_time==it), "varfc" := modelfit$mean]
}
return(horizon_fcs)
}
variance_fcs <- horizon_var_fcs(zone_data, 3, split_date)
which(is.na(zone_h_ts$errors))
View(zone_h_ts)
(-1.954591772 + 0.728788607)/2
zdata[, test_errors := approx(.I, errors, .I)$y] ## interpolate missing values in  TARGETVAR
zone_h_ts[, test_errors := approx(.I, errors, .I)$y] ## interpolate missing values in  TARGETVAR
View(zone_h_ts)
zone_h_ts[, errors := approx(.I, errors, .I)$y] ## interpolate missing values in  TARGETVAR
View(variance_fcs)
meanvardt <- merge(zone_data, variance_fcs, by=c("issue_time", "target_time")) # means and variances in one data.table.
View(meanvardt)
require(data.table)
require(forecast)
require(rstudioapi)
require(doParallel)
require(ProbCast)
setwd(dirname(getActiveDocumentContext()$path))
zones <- c(1:10)
horizons <- c(1:6) # forecast 1 to 6 hours ahead
split_date <- as.POSIXct("2012-12-31 12:00") # split the training/testing data here
eps <- 0.01
LL <- log(eps/(1-eps)) # lower and upper limits in transformed space.
UL <- log((1-eps)/eps)
qs <- seq(0.05, 0.95, 0.05) # quantiles we will produce forecasts for.
load("../VAR/all_sites_power.rda") # this is power in transformed space already
setnames(alldata, 'timestamp', 'target_time') # so this matches with training_mean_fcs colnames.
################ function to get exponential smoothing forecasts of variance ################
horizon_var_fcs <- function(zonedata, H, splitdate){
require(data.table)
require(forecast)
zone_h_ts <- zonedata[Horizon==H]
zone_h_ts <- zone_h_ts[order(issue_time)]
zone_h_ts[, errors := approx(.I, errors, .I)$y] ## interpolate missing values in errors
horizon_fcs <- copy(zone_h_ts[issue_time>splitdate, .(issue_time,target_time)])
test_times <- horizon_fcs$target_time
for (it in test_times){
# fit exponential smoothing to all data where we have forecast and actual power before it (ie before target_time<=it)
data <-zone_h_ts[target_time <= it,]
modelfit <- ses(ts(zone_h_ts[target_time <= it, errors]), h=1, inital='optimal')
horizon_fcs[(issue_time==it), "varfc" := modelfit$mean]
}
return(horizon_fcs)
}
z <- 1
## load the site mean forecasts
load(paste0("./mean_forecasts_zone",z,".rda"))
## want to get residuals for each zone.
power_fcts <- alldata[target_time %in% all_mean_fcs$target_time] # keep only the timestamps we also have forecasts for
## find the residuals
zone_data <- merge(power_fcts[,.(target_time, power=get(paste0("zone",z,"power")))],
all_mean_fcs[, .(issue_time, target_time, Horizon, meanfcs=mean_fc)], by='target_time')
zone_data[,errors :=(power-meanfcs)]
variance_fcs <- horizon_var_fcs(zone_data, 3, split_date)
meanvardt <- merge(zone_data, variance_fcs, by=c("issue_time", "target_time")) # means and variances in one data.table.
View(meanvardt)
meanvardt[, varfc := abs(varfc)] # standard deviations must be positive
meanvardt[, ActualPower := 1/(1+exp(-power))]
## now we have a mean and a variance for every time point, make the quantile forecasts.
z_quantiles <- data.table()
for (q in qs){
z_quantiles[, paste0('q',q*100) := qnorm(p=q, mean=meanvardt$meanfcs, sd=meanvardt$varfc)]
}
class(z_quantiles) <- c("MultiQR", class(z_quantiles)) # make a multiQR object so we can sort the quantiles.
z_quantiles <- SortQuantiles(z_quantiles, Limits=list(U=UL, L=LL)) # make sure quantiles don't cross and crop at eps (in transformed space)
z_quantiles <- 1/(1+exp(-z_quantiles)) ## now transform back to 'power' space. However, this operation returns a data.frame object so:
class(z_quantiles) <- c("MultiQR", "data.table", class(z_quantiles)) # make a multiQR object again (SortQuantiles just returns a data.table).
other_info <- meanvardt[, .(issue_time, target_time, Horizon, ActualPower)] # all the other information needed to evaluate the quantiles.
reliability(z_quantiles, realisations = other_info$ActualPower)
require(data.table)
require(forecast)
require(rstudioapi)
require(doParallel)
require(ProbCast)
setwd(dirname(getActiveDocumentContext()$path))
zones <- c(1:10)
horizons <- c(1:6) # forecast 1 to 6 hours ahead
split_date <- as.POSIXct("2012-12-31 12:00") # split the training/testing data here
eps <- 0.01
LL <- log(eps/(1-eps)) # lower and upper limits in transformed space.
UL <- log((1-eps)/eps)
qs <- seq(0.05, 0.95, 0.05) # quantiles we will produce forecasts for.
load("../VAR/all_sites_power.rda") # this is power in transformed space already
setnames(alldata, 'timestamp', 'target_time') # so this matches with training_mean_fcs colnames.
################ function to get exponential smoothing forecasts of variance ################
horizon_var_fcs <- function(zonedata, H, splitdate){
require(data.table)
require(forecast)
zone_h_ts <- zonedata[Horizon==H]
zone_h_ts <- zone_h_ts[order(issue_time)]
zone_h_ts[, errors := approx(.I, errors, .I)$y] ## interpolate missing values in errors
horizon_fcs <- copy(zone_h_ts[issue_time>splitdate, .(issue_time,target_time)])
test_times <- horizon_fcs$target_time
for (it in test_times){
# fit exponential smoothing to all data where we have forecast and actual power before it (ie before target_time<=it)
data <-zone_h_ts[target_time <= it,]
modelfit <- ses(ts(zone_h_ts[target_time <= it, errors]), h=1, inital='optimal')
horizon_fcs[(issue_time==it), "varfc" := modelfit$mean]
}
return(horizon_fcs)
}
# test <- horizon_var_fcs(zone_data, 1)
#############################################################################################
for (z in zones){
print (z)
## load the site mean forecasts
load(paste0("./mean_forecasts_zone",z,".rda"))
## want to get residuals for each zone.
power_fcts <- alldata[target_time %in% all_mean_fcs$target_time] # keep only the timestamps we also have forecasts for
## find the residuals
zone_data <- merge(power_fcts[,.(target_time, power=get(paste0("zone",z,"power")))],
all_mean_fcs[, .(issue_time, target_time, Horizon, meanfcs=mean_fc)], by='target_time')
zone_data[,errors :=(power-meanfcs)]
cores <- detectCores()
cl <- makeCluster(cores-2)
registerDoParallel(cl)
start_time <- Sys.time()
variance_fcs <- foreach(H = horizons) %dopar% {
horizon_var_fcs(zone_data, H, split_date)
}
print (Sys.time() - start_time)
stopCluster(cl)
variance_fcs <- rbindlist(variance_fcs)
meanvardt <- merge(zone_data, variance_fcs, by=c("issue_time", "target_time")) # means and variances in one data.table.
meanvardt[, varfc := abs(varfc)] # standard deviations must be positive
meanvardt[, ActualPower := 1/(1+exp(-power))]
## now we have a mean and a variance for every time point, make the quantile forecasts.
z_quantiles <- data.table()
for (q in qs){
z_quantiles[, paste0('q',q*100) := qnorm(p=q, mean=meanvardt$meanfcs, sd=meanvardt$varfc)]
}
class(z_quantiles) <- c("MultiQR", class(z_quantiles)) # make a multiQR object so we can sort the quantiles.
z_quantiles <- SortQuantiles(z_quantiles, Limits=list(U=UL, L=LL)) # make sure quantiles don't cross and crop at eps (in transformed space)
z_quantiles <- 1/(1+exp(-z_quantiles)) ## now transform back to 'power' space. However, this operation returns a data.frame object so:
class(z_quantiles) <- c("MultiQR", "data.table", class(z_quantiles)) # make a multiQR object again (SortQuantiles just returns a data.table).
other_info <- meanvardt[, .(issue_time, target_time, Horizon, ActualPower)] # all the other information needed to evaluate the quantiles.
## make a list with the MultiQR object and the time info data.table
EMD_fcs <-list(z_quantiles,other_info)
save(EMD_fcs, file=paste0("./zone",z,"_qs_expsmoothvar.rda"))
}
View(meanvardt)
View(meanvardt)
h_meanvardt <- meanvardt[Horizon==3]
plot(h_meanvardt[c(200:300),issue_time], h_meanvardt[c(200:300), errors], type='l')
lines(h_meanvardt[c(200:300),issue_time], h_meanvardt[c(200:300), varfc], type='l', col='r')
lines(h_meanvardt[c(200:300),issue_time], h_meanvardt[c(200:300), varfc], type='l', col='red')
plot(h_meanvardt[c(200:300),issue_time], abs(h_meanvardt[c(200:300), errors]), type='l')
lines(h_meanvardt[c(200:300),issue_time], h_meanvardt[c(200:300), varfc], type='l', col='red')
## now we have a mean and a variance for every time point, make the quantile forecasts.
z_quantiles <- data.table()
for (q in qs){
z_quantiles[, paste0('q',q*100) := qnorm(p=q, mean=meanvardt$meanfcs, sd=meanvardt$varfc)]
}
class(z_quantiles) <- c("MultiQR", class(z_quantiles)) # make a multiQR object so we can sort the quantiles.
z_quantiles <- SortQuantiles(z_quantiles, Limits=list(U=UL, L=LL)) # make sure quantiles don't cross and crop at eps (in transformed space)
class(z_quantiles)
z_quantiles <- SortQuantiles(z_quantiles, Limits=c(U=UL, L=LL)) # make sure quantiles don't cross and crop at eps (in transformed space)
Limits=list(U=UL, L=LL)
Limits$U
Limits$L
SortQuantiles <- function(data,Limits=NULL){
### Check cols are in correct order
if(is.unsorted(as.numeric(gsub(colnames(data),pattern = "q",replacement = "")))){
stop("Columns are not sorted. Check format.")
}
temp <- as.matrix(data)
temp <- t(apply(temp,1,sort))
if(!is.null(Limits)){
temp[temp>Limits$U] <- Limits$U
temp[temp<Limits$L] <- Limits$L
}
temp <- data.frame(temp)
colnames(temp) <- colnames(data)
class(temp) <- c("MultiQR","data.frame")
return(temp)
}
z_quantiles <- SortQuantiles(z_quantiles, Limits=c(U=UL, L=LL)) # make sure quantiles don't cross and crop at eps (in transformed space)
z_quantiles <- SortQuantiles(z_quantiles, Limits=list(U=UL, L=LL)) # make sure quantiles don't cross and crop at eps (in transformed space)
data <- z_quantiles
View(Limits)
### Check cols are in correct order
if(is.unsorted(as.numeric(gsub(colnames(data),pattern = "q",replacement = "")))){
stop("Columns are not sorted. Check format.")
}
temp <- as.matrix(data)
temp <- t(apply(temp,1,sort))
!is.null(Limits)
temp[temp>Limits$U] <- Limits$U
temp[temp>Limits$U] <- 4
class(temp)
