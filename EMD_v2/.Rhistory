require(data.table)
require(forecast)
require(rstudioapi)
require(doParallel)
require(ProbCast)
setwd(dirname(getActiveDocumentContext()$path))
zones <- c(1:10)
horizons <- c(1:6) # forecast 1 to 6 hours ahead
split_date <- as.POSIXct("2012-12-31 12:00") # split the training/testing data here
eps <- 0.01
LL <- log(eps/(1-eps)) # lower and upper limits in transformed space.
UL <- log((1-eps)/eps)
qs <- seq(0.05, 0.95, 0.05) # quantiles we will produce forecasts for.
load("../VAR/all_sites_power.rda") # this is power in transformed space already
setnames(alldata, 'timestamp', 'target_time') # so this matches with training_mean_fcs colnames.
################ function to get exponential smoothing forecasts of variance ################
horizon_var_fcs <- function(zonedata, H){
require(data.table)
require(forecast)
zone_h_ts <- zonedata[Horizon==H]
zone_h_ts <- zone_h_ts[order(issue_time)]
horizon_fcs <- data.table(issue_time=zone_h_ts[issue_time>split_date,issue_time], target_time=zone_h_ts[issue_time>split_date, target_time])
test_times <- zone_h_ts[issue_time > split_date, issue_time]
for (it in test_times){
# fit exponential smoothing to all data before it
modelfit <- ses(ts(zone_h_ts[issue_time <= it, errors]), h=1, inital='optimal')
horizon_fcs[(issue_time==it) & (target_time==zone_h_ts[issue_time==it, target_time]), "varfc" := modelfit$mean]
}
return(horizon_fcs)
}
# test <- horizon_var_fcs(zone_data, 1)
#############################################################################################
for (z in c(2:10)){
print (z)
## load the site mean forecasts
load(paste0("./mean_forecasts_zone",z,".rda"))
## want to get residuals for each zone.
power_fcts <- alldata[target_time %in% all_mean_fcs$target_time] # keep only the timestamps we also have forecasts for
## find the variance of the residuals from the training set (in transformed space)
zone_data <- merge(power_fcts[,.(target_time, power=get(paste0("zone",z,"power")))],
all_mean_fcs[, .(issue_time, target_time, Horizon, meanfcs=mean_fc)])
zone_data[,errors :=(power-meanfcs)]
cores <- detectCores()
cl <- makeCluster(cores-2)
registerDoParallel(cl)
start_time <- Sys.time()
variance_fcs <- foreach(H = horizons) %dopar% {
horizon_var_fcs(zone_data, H)
}
print (Sys.time() - start_time)
stopCluster(cl)
variance_fcs <- rbindlist(variance_fcs)
meanvardt <- merge(zone_data, variance_fcs, by=c("issue_time", "target_time")) # means and variances in one data.table.
meanvardt[, varfc := abs(varfc)] # standard deviations must be positive
meanvardt[, ActualPower := 1/(1+exp(-power))]
## now we have a mean and a variance for every time point, make the quantile forecasts.
z_quantiles <- data.table()
for (q in qs){
z_quantiles[, paste0('q',q*100) := qnorm(p=q, mean=meanvardt$meanfcs, sd=meanvardt$varfc)]
}
class(z_quantiles) <- c("MultiQR", class(z_quantiles)) # make a multiQR object so we can sort the quantiles.
z_quantiles <- SortQuantiles(z_quantiles, Limits=list(U=UL, L=LL)) # make sure quantiles don't cross and crop at eps (in transformed space)
z_quantiles <- 1/(1+exp(-z_quantiles)) ## now transform back to 'power' space. However, this operation returns a data.frame object so:
class(z_quantiles) <- c("MultiQR", "data.table", class(z_quantiles)) # make a multiQR object again (SortQuantiles just returns a data.table).
other_info <- meanvardt[, .(issue_time, target_time, Horizon, ActualPower)] # all the other information needed to evaluate the quantiles.
## make a list with the MultiQR object and the time info data.table
EMD_fcs <-list(z_quantiles,other_info)
save(EMD_fcs, file=paste0("./zone",z,"_qs_expsmoothvar.rda"))
}
require(data.table)
require(ProbCast)
require(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
zones <- c(1:10)
horizons <- c(1:6) # forecast 1 to 6 hours ahead
eps <- 0.01
LL <- log(eps/(1-eps)) # lower and upper limits in transformed space.
UL <- log((1-eps)/eps)
qs <- seq(0.05, 0.95, 0.05) # quantiles we will produce forecasts for.
split_date <- as.POSIXct("2012-12-31 12:00") # split the training/testing data here
z <- 1
## load the site mean forecasts
load(paste0("./mean_forecasts_zone",z,".rda"))
## want to get residuals for each zone.
power_fcts <- alldata[target_time %in% all_mean_fcs$target_time] # keep only the timestamps we also have forecasts for
## find the residuals
zone_data <- merge(power_fcts[,.(target_time, power=get(paste0("zone",z,"power")))],
all_mean_fcs[, .(issue_time, target_time, Horizon, meanfcs=mean_fc)])
load("../VAR/all_sites_power.rda") # this is power in transformed space already
setnames(alldata, 'timestamp', 'target_time') # so this matches with training_mean_fcs colnames.
## load the site mean forecasts
load(paste0("./mean_forecasts_zone",z,".rda"))
## want to get residuals for each zone.
power_fcts <- alldata[target_time %in% all_mean_fcs$target_time] # keep only the timestamps we also have forecasts for
## find the residuals
zone_data <- merge(power_fcts[,.(target_time, power=get(paste0("zone",z,"power")))],
all_mean_fcs[, .(issue_time, target_time, Horizon, meanfcs=mean_fc)])
zone_data[,errors :=(power-meanfcs)]
zone_sd <- sd(zone_data[issue_time <= split_date, errors]) # standard deviation of the residuals
zone_data[issue_time <= split_date, sd := lapply(errors, sd), by=Horizon]
View(zone_data)
plot(is.na(zone_data$sd))
train_data <- zone_data[issue_time <= split_date]
train_data[, sd := sd(errors), by=Horizon]
View(train_data)
train_data[, .(sd := sd(errors)), by=Horizon]
train_data[, .(sd = sd(errors)), by=Horizon]
sdevs <- train_data[, .(sd = sd(errors)), by=Horizon]
class(sdevs)
zone_test_data <- zone_data[issue_time > split_date,]
test <- merge(zone_test_data, sdevs, by=Horizon)
test <- merge(zone_test_data, sdevs, by="Horizon")
View(test)
require(data.table)
require(ProbCast)
require(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
zones <- c(1:10)
horizons <- c(1:6) # forecast 1 to 6 hours ahead
split_date <- as.POSIXct("2012-12-31 12:00") # split the training/testing data here
eps <- 0.01
LL <- log(eps/(1-eps)) # lower and upper limits in transformed space.
UL <- log((1-eps)/eps)
qs <- seq(0.05, 0.95, 0.05) # quantiles we will produce forecasts for.
load("../VAR/all_sites_power.rda") # this is power in transformed space already
setnames(alldata, 'timestamp', 'target_time') # so this matches with training_mean_fcs colnames.
z <- 1
## load the site mean forecasts
load(paste0("./mean_forecasts_zone",z,".rda"))
## want to get residuals for each zone.
power_fcts <- alldata[target_time %in% all_mean_fcs$target_time] # keep only the timestamps we also have forecasts for
## find the residuals
zone_data <- merge(power_fcts[,.(target_time, power=get(paste0("zone",z,"power")))],
all_mean_fcs[, .(issue_time, target_time, Horizon, meanfcs=mean_fc)])
zone_data[,errors :=(power-meanfcs)]
zone_train_data <- zone_data[issue_time <= split_date]
sdevs <- zone_train_data[, .(sd = sd(errors)), by=Horizon]
zone_test_data <- zone_data[issue_time > split_date,]
test <- merge(zone_test_data, sdevs, by="Horizon")
## mean forecasts in 'power' (untransformed) space, needed to generate quantile forecasts
zone_test_data <- testing_mean_fcs[, .(issue_time, target_time, Horizon, mean_T_fcs=get(paste0("zone",z,"power_meanfcs")))]
zone_test_data <- merge(zone_test_data, alldata[,.(target_time, Tpower=get(paste0("zone",z,"power")))], by='target_time')
zone_test_data[, ActualPower := 1/(1+exp(-Tpower))]
## now make quantile forecasts (in transformed space first) for this zone
z_quantiles <- data.table()
for (q in qs){
z_quantiles[, paste0('q',q*100) := qnorm(p=q, mean=zone_test_data$mean_T_fcs, sd=zone_sd)]
}
class(z_quantiles) <- c("MultiQR", class(z_quantiles)) # make a multiQR object so we can sort the quantiles.
zone_test_data <- merge(zone_test_data, sdevs, by="Horizon")
View(zone_test_data)
zones <- c(1:10)
horizons <- c(1:6) # forecast 1 to 6 hours ahead
split_date <- as.POSIXct("2012-12-31 12:00") # split the training/testing data here
eps <- 0.01
LL <- log(eps/(1-eps)) # lower and upper limits in transformed space.
UL <- log((1-eps)/eps)
qs <- seq(0.05, 0.95, 0.05) # quantiles we will produce forecasts for.
load("../VAR/all_sites_power.rda") # this is power in transformed space already
setnames(alldata, 'timestamp', 'target_time') # so this matches with training_mean_fcs colnames.
z <- 1
## load the site mean forecasts
load(paste0("./mean_forecasts_zone",z,".rda"))
## want to get residuals for each zone.
power_fcts <- alldata[target_time %in% all_mean_fcs$target_time] # keep only the timestamps we also have forecasts for
## find the residuals
zone_data <- merge(power_fcts[,.(target_time, power=get(paste0("zone",z,"power")))],
all_mean_fcs[, .(issue_time, target_time, Horizon, meanfcs=mean_fc)])
zone_data[,errors :=(power-meanfcs)]
zone_train_data <- zone_data[issue_time <= split_date]
sdevs <- zone_train_data[, .(sd = sd(errors)), by=Horizon]
zone_test_data <- zone_data[issue_time > split_date,]
zone_test_data <- merge(zone_test_data, sdevs, by="Horizon")
View(zone_test_data)
zone_test_data[, ActualPower := 1/(1+exp(-power))]
## now make quantile forecasts (in transformed space first) for this zone
z_quantiles <- data.table()
for (q in qs){
z_quantiles[, paste0('q',q*100) := qnorm(p=q, mean=zone_test_data$meanfcs, sd=zone_test_data$sd)]
}
class(z_quantiles) <- c("MultiQR", class(z_quantiles)) # make a multiQR object so we can sort the quantiles.
z_quantiles <- SortQuantiles(z_quantiles, Limits=list(U=UL, L=LL)) # make sure quantiles don't cross and crop at eps (in transformed space)
z_quantiles <- 1/(1+exp(-z_quantiles)) ## now transform back to 'power' space. However, this operation returns a data.frame object so:
class(z_quantiles) <- c("MultiQR", "data.table", class(z_quantiles)) # make a multiQR object again (SortQuantiles just returns a data.table).
other_info <- zone_test_data[, .(issue_time, target_time, Horizon, ActualPower)] # all the other information needed to evaluate the quantiles.
## make a list with the MultiQR object and the time info data.table
VAR_fcs <-list(z_quantiles,other_info)
## make a list with the MultiQR object and the time info data.table
EMD_fcs <-list(z_quantiles,other_info)
save(EMD_fcs, file=paste0("./zone",z,"_qs_constvar.rda"))
require(data.table)
require(ProbCast)
require(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
zones <- c(1:10)
horizons <- c(1:6) # forecast 1 to 6 hours ahead
split_date <- as.POSIXct("2012-12-31 12:00") # split the training/testing data here
eps <- 0.01
LL <- log(eps/(1-eps)) # lower and upper limits in transformed space.
UL <- log((1-eps)/eps)
qs <- seq(0.05, 0.95, 0.05) # quantiles we will produce forecasts for.
load("../VAR/all_sites_power.rda") # this is power in transformed space already
setnames(alldata, 'timestamp', 'target_time') # so this matches with training_mean_fcs colnames.
for (z in c(2:10)){
print (z)
## load the site mean forecasts
load(paste0("./mean_forecasts_zone",z,".rda"))
## want to get residuals for each zone.
power_fcts <- alldata[target_time %in% all_mean_fcs$target_time] # keep only the timestamps we also have forecasts for
## find the residuals
zone_data <- merge(power_fcts[,.(target_time, power=get(paste0("zone",z,"power")))],
all_mean_fcs[, .(issue_time, target_time, Horizon, meanfcs=mean_fc)])
zone_data[,errors :=(power-meanfcs)]
zone_train_data <- zone_data[issue_time <= split_date]
sdevs <- zone_train_data[, .(sd = sd(errors)), by=Horizon]
zone_test_data <- zone_data[issue_time > split_date,]
zone_test_data <- merge(zone_test_data, sdevs, by="Horizon")
zone_test_data[, ActualPower := 1/(1+exp(-power))]
## now make quantile forecasts (in transformed space first) for this zone
z_quantiles <- data.table()
for (q in qs){
z_quantiles[, paste0('q',q*100) := qnorm(p=q, mean=zone_test_data$meanfcs, sd=zone_test_data$sd)]
}
class(z_quantiles) <- c("MultiQR", class(z_quantiles)) # make a multiQR object so we can sort the quantiles.
z_quantiles <- SortQuantiles(z_quantiles, Limits=list(U=UL, L=LL)) # make sure quantiles don't cross and crop at eps (in transformed space)
z_quantiles <- 1/(1+exp(-z_quantiles)) ## now transform back to 'power' space. However, this operation returns a data.frame object so:
class(z_quantiles) <- c("MultiQR", "data.table", class(z_quantiles)) # make a multiQR object again (SortQuantiles just returns a data.table).
other_info <- zone_test_data[, .(issue_time, target_time, Horizon, ActualPower)] # all the other information needed to evaluate the quantiles.
## make a list with the MultiQR object and the time info data.table
EMD_fcs <-list(z_quantiles,other_info)
save(EMD_fcs, file=paste0("./zone",z,"_qs_constvar.rda"))
}
